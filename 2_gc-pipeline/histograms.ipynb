{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "72aa9012-c901-475d-af55-d2d8279e3b96",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Setup\n",
    "!pip install --quiet --upgrade pip\n",
    "\n",
    "# Install the dependencies.\n",
    "!pip install --quiet -r gdal_req.txt\n",
    "\n",
    "# Restart the runtime by ending the process.\n",
    "exit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c3d93dbd-4fd4-4d22-a4fb-bf2715b1f291",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import rasterio\n",
    "from google.cloud import storage\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from utils.constants import  BUCKET, IMG_SOURCE_PREFIX, HIST_DEST_PREFIX\n",
    "from serving_hist.hist_data import list_blobs_with_prefix, load_tiff_from_gcs_mem, download_and_process_tiff,load_tiff_from_gcs_temp\n",
    "import io\n",
    "import google.auth\n",
    "from rasterio.io import MemoryFile\n",
    "from osgeo import gdal\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c2971217-5d41-48ec-af03-7b960f33e742",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# SETUP\n",
    "credentials, _ = google.auth.default()\n",
    "\n",
    "bucket_name = BUCKET\n",
    "\n",
    "directory_prefix = IMG_SOURCE_PREFIX\n",
    "output_prefix = HIST_DEST_PREFIX\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "217d8148-8323-4495-96a1-94b039cb7b6b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Data processing example\n",
    "image_name = directory_prefix\n",
    "# List all files from 2023\n",
    "\n",
    "image_name += \"Orleans\"\n",
    "image_name += \"_2017\"\n",
    "image_name += \"_9-10_100\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0e094eba-455e-468b-8d9b-d4f169c68c73",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "blobs = list_blobs_with_prefix(bucket_name, image_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "df55ef24-9b3c-4398-88a7-c5d74a83613a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_blob_into_memory(bucket_name, blob_name):\n",
    "    \"\"\"Downloads a blob into memory.\"\"\"\n",
    "    # The ID of your GCS bucket\n",
    "    # bucket_name = \"your-bucket-name\"\n",
    "\n",
    "    # The ID of your GCS object\n",
    "    # blob_name = \"storage-object-name\"\n",
    "\n",
    "    storage_client = storage.Client()\n",
    "\n",
    "    bucket = storage_client.bucket(bucket_name)\n",
    "\n",
    "    # Construct a client side representation of a blob.\n",
    "    # Note `Bucket.blob` differs from `Bucket.get_blob` as it doesn't retrieve\n",
    "    # any content from Google Cloud Storage. As we don't need additional data,\n",
    "    # using `Bucket.blob` is preferred here.\n",
    "    blob = bucket.blob(blob_name)\n",
    "    contents = blob.download_as_bytes()\n",
    "    return contents\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "943d4668-145e-4594-8e02-fe5719b3de9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load all bands of one image into memory: 0.3352 seconds\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "blob_name = r'images/Orleans_2017_9-10_100_0000000000-0000008192.tif'\n",
    "test = download_blob_into_memory(bucket_name, blob_name)\n",
    "\n",
    "end_time = time.time()\n",
    "execution_time = end_time - start_time\n",
    "print(f\"Load all bands of one image into memory: {execution_time:.4f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fd146a34-7243-445e-a597-bc7e574079b3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'vgnn'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bucket_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fc24e27a-65d7-4343-885d-5a750242d33c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11570361"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1fe0b052-fd4d-4481-b97c-5bf9f54c05d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Convery one band into array: 11.3441 seconds\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "with MemoryFile(test) as memfile:\n",
    "    with memfile.open() as src:\n",
    "        array = src.read(1)\n",
    "        \n",
    "end_time = time.time()\n",
    "execution_time = end_time - start_time\n",
    "print(f\"Convery one band into array: {execution_time:.4f} seconds\")        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "eff3bc47-e984-446f-8b37-c84a1f8e29c2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Using gdal\n",
    "def read_tif_from_gcs(bucket_name, blob_name):\n",
    "    \"\"\"\n",
    "    Reads tif image from Google Cloud Storage into a tensor and attempts to print date information.\n",
    "    \"\"\"\n",
    "    # Use exceptions for error handling\n",
    "    gdal.UseExceptions()\n",
    "\n",
    "    # Construct the GCS path\n",
    "    gcs_path = f'/vsigs/{bucket_name}/{blob_name}'\n",
    "\n",
    "    logging.info(f\"Attempting to open: {gcs_path}\")\n",
    "\n",
    "    try:\n",
    "        gdal_dataset = gdal.Open(gcs_path)\n",
    "    except RuntimeError as e:\n",
    "        logging.error(f\"Error opening {gcs_path} with gdal: {str(e)}\")\n",
    "        \n",
    "        # Check if the file exists in the bucket\n",
    "        storage_client = storage.Client()\n",
    "        bucket = storage_client.bucket(bucket_name)\n",
    "        blob = bucket.blob(blob_name)\n",
    "        \n",
    "        if blob.exists():\n",
    "            logging.info(f\"The file {blob_name} exists in the bucket, but GDAL couldn't open it.\")\n",
    "        else:\n",
    "            logging.info(f\"The file {blob_name} does not exist in the bucket {bucket_name}.\")\n",
    "        \n",
    "        return None\n",
    "\n",
    "    # Read image data\n",
    "    gdal_result = gdal_dataset.ReadAsArray().astype(np.uint16)\n",
    "    if len(gdal_result.shape) == 2:\n",
    "        gdal_result = np.reshape(gdal_result, [1] + list(gdal_result.shape))\n",
    "    image_data = np.transpose(gdal_result, [1, 2, 0])\n",
    "\n",
    "    logging.info(f\"Successfully read image with shape: {image_data.shape}\")\n",
    "\n",
    "    return image_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6ffdad6-c53d-46d7-99db-6d02d77a6bfd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "gdal_array = read_tif_from_gcs(BUCKET, r'images/Orleans_2017_9-10_100_0000000000-0000008192.tif')\n",
    "\n",
    "end_time = time.time()\n",
    "execution_time = end_time - start_time\n",
    "print(f\"Gdal array: {execution_time:.4f} seconds\")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7e58d9e8-bb70-4f4c-931e-d045f9e421e0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "gdal_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d5749082-a27a-470b-99ff-78308ce42c5b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "array_clean = np.nan_to_num(array, nan=0.0).astype(np.uint16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9568f49f-dc74-45a5-87e2-260d756d2ac1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_histogram_skip_nan(image, bins=256, range=(0, 255)):\n",
    "    # Flatten the image and remove NaN values\n",
    "    flat_image = image.flatten()\n",
    "    \n",
    "    zero_mask = np.any(flat_image != 0.0, -1)\n",
    "    non_nan_values = flat_image[~np.isnan(flat_image)]\n",
    "    \n",
    "    # Create histogram\n",
    "    hist, bin_edges = np.histogram(non_nan_values, bins=bins, density=False)\n",
    "    \n",
    "    return hist, bin_edges\n",
    "\n",
    "bins = len(np.linspace(1, 2200, 33))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "719cb2bc-6435-40a6-8c3d-9574380cab31",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create single band histogram: 1.1596 seconds\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "create_histogram_skip_nan(array_clean)\n",
    "\n",
    "end_time = time.time()\n",
    "execution_time = end_time - start_time\n",
    "print(f\"Create single band histogram: {execution_time:.4f} seconds\")    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5b84949-d90e-45db-9701-760268e32268",
   "metadata": {},
   "outputs": [],
   "source": [
    "import rasterio\n",
    "import numpy as np\n",
    "from google.cloud import storage\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "\n",
    "def process_band(src, band):\n",
    "    total_sum = 0\n",
    "    total_count = 0\n",
    "    histograms = []\n",
    "\n",
    "    for ji, window in src.block_windows(band):\n",
    "        data = src.read(band, window=window)\n",
    "        valid_data = data[~np.isnan(data)]\n",
    "        \n",
    "        if valid_data.size > 0:\n",
    "            total_sum += np.sum(valid_data)\n",
    "            total_count += valid_data.size\n",
    "            hist, _ = np.histogram(valid_data, bins=256, range=(0, 255))\n",
    "            histograms.append(hist)\n",
    "\n",
    "    mean = total_sum / total_count if total_count > 0 else np.nan\n",
    "    combined_histogram = np.sum(histograms, axis=0) if histograms else np.zeros(256)\n",
    "    return band, mean, combined_histogram\n",
    "\n",
    "def process_tiff_parallel(bucket_name, blob_name, max_workers=4):\n",
    "    storage_client = storage.Client()\n",
    "    bucket = storage_client.bucket(bucket_name)\n",
    "    blob = bucket.blob(blob_name)\n",
    "\n",
    "    with blob.open(\"rb\") as f:\n",
    "        with rasterio.open(f) as src:\n",
    "            num_bands = src.count\n",
    "            \n",
    "            with ThreadPoolExecutor(max_workers=max_workers) as executor:\n",
    "                future_to_band = {executor.submit(process_band, src, band): band for band in range(1, num_bands + 1)}\n",
    "                results = []\n",
    "                \n",
    "                for future in as_completed(future_to_band):\n",
    "                    band = future_to_band[future]\n",
    "                    try:\n",
    "                        result = future.result()\n",
    "                        results.append(result)\n",
    "                    except Exception as exc:\n",
    "                        print(f'Band {band} generated an exception: {exc}')\n",
    "\n",
    "    return sorted(results, key=lambda x: x[0])  # Sort results by band number\n",
    "\n",
    "# Usage\n",
    "bucket_name = \"your-bucket-name\"\n",
    "blob_name = \"path/to/your/large_image.tif\"\n",
    "\n",
    "results = process_tiff_parallel(bucket_name, blob_name)\n",
    "for band, mean, histogram in results:\n",
    "    print(f\"Band {band}:\")\n",
    "    print(f\"  Mean: {mean}\")\n",
    "    print(f\"  Histogram sum: {np.sum(histogram)}\")"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "conda-env-gdal_conda-gdal_conda",
   "name": "workbench-notebooks.m125",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/workbench-notebooks:m125"
  },
  "kernelspec": {
   "display_name": "GDAL_kernel (Local)",
   "language": "python",
   "name": "conda-env-gdal_conda-gdal_conda"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
