{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ea876282-7e0d-4a5e-be56-0b31f49f3992",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Setup\n",
    "!pip install --quiet --upgrade pip\n",
    "\n",
    "# Install the dependencies.\n",
    "!pip install --quiet -r requirements.txt\n",
    "\n",
    "# Restart the runtime by ending the process.\n",
    "exit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e5d9bc1e-c419-4350-a556-1a76cb21ab39",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from google.cloud import storage\n",
    "import google.auth\n",
    "from serving.constants import  BUCKET, IMG_SOURCE_PREFIX, HIST_DEST_PREFIX, NUM_BANDS, HIST_BINS_LIST, SCALE, CROP\n",
    "from serving.common import list_blobs_with_prefix\n",
    "from serving.hist_training import create_hist_dataset, LstmModel, train_and_evaluate, create_data_sample, get_labels\n",
    "import logging\n",
    "import io\n",
    "import itertools\n",
    "from google.cloud import storage\n",
    "import google.auth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7c83aac7-7acf-435f-8cc9-e24d51bf3a5b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# SETUP\n",
    "credentials, _ = google.auth.default()\n",
    "bucket_name = BUCKET\n",
    "directory_prefix = IMG_SOURCE_PREFIX\n",
    "output_prefix = HIST_DEST_PREFIX\n",
    "labels = \"labels_combined.npy\"\n",
    "batch_size = 6\n",
    "\n",
    "client = storage.Client()\n",
    "bucket = client.get_bucket(bucket_name)\n",
    "\n",
    "logging.basicConfig(filename=\"cerate_dataset.log\",level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "\n",
    "counties = [\"Lancaster\", \"Crawford\", \"Orleans\", \"Tulare\", \"Wharton\", \"Story\", \"Canyon\", \"Kit Carson\"]\n",
    "years = range(2017,2019)\n",
    "months = [5,7,9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f0a26a19-410d-4e78-8e7c-ead300283a65",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>commodity_desc</th>\n",
       "      <th>reference_period_desc</th>\n",
       "      <th>year</th>\n",
       "      <th>state_name</th>\n",
       "      <th>county_name</th>\n",
       "      <th>target</th>\n",
       "      <th>source_file</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CORN</td>\n",
       "      <td>YEAR</td>\n",
       "      <td>2016</td>\n",
       "      <td>ALABAMA</td>\n",
       "      <td>BALDWIN</td>\n",
       "      <td>152.9</td>\n",
       "      <td>USDA_Corn_County_2016.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CORN</td>\n",
       "      <td>YEAR</td>\n",
       "      <td>2016</td>\n",
       "      <td>ALABAMA</td>\n",
       "      <td>BARBOUR</td>\n",
       "      <td>188.9</td>\n",
       "      <td>USDA_Corn_County_2016.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CORN</td>\n",
       "      <td>YEAR</td>\n",
       "      <td>2016</td>\n",
       "      <td>ALABAMA</td>\n",
       "      <td>CHEROKEE</td>\n",
       "      <td>92.3</td>\n",
       "      <td>USDA_Corn_County_2016.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CORN</td>\n",
       "      <td>YEAR</td>\n",
       "      <td>2016</td>\n",
       "      <td>ALABAMA</td>\n",
       "      <td>CLEBURNE</td>\n",
       "      <td>125.0</td>\n",
       "      <td>USDA_Corn_County_2016.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CORN</td>\n",
       "      <td>YEAR</td>\n",
       "      <td>2016</td>\n",
       "      <td>ALABAMA</td>\n",
       "      <td>COFFEE</td>\n",
       "      <td>104.5</td>\n",
       "      <td>USDA_Corn_County_2016.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>CORN</td>\n",
       "      <td>YEAR</td>\n",
       "      <td>2016</td>\n",
       "      <td>ALABAMA</td>\n",
       "      <td>COLBERT</td>\n",
       "      <td>126.2</td>\n",
       "      <td>USDA_Corn_County_2016.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>CORN</td>\n",
       "      <td>YEAR</td>\n",
       "      <td>2016</td>\n",
       "      <td>ALABAMA</td>\n",
       "      <td>CONECUH</td>\n",
       "      <td>116.7</td>\n",
       "      <td>USDA_Corn_County_2016.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>CORN</td>\n",
       "      <td>YEAR</td>\n",
       "      <td>2016</td>\n",
       "      <td>ALABAMA</td>\n",
       "      <td>COVINGTON</td>\n",
       "      <td>108.1</td>\n",
       "      <td>USDA_Corn_County_2016.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>CORN</td>\n",
       "      <td>YEAR</td>\n",
       "      <td>2016</td>\n",
       "      <td>ALABAMA</td>\n",
       "      <td>CULLMAN</td>\n",
       "      <td>117.2</td>\n",
       "      <td>USDA_Corn_County_2016.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>CORN</td>\n",
       "      <td>YEAR</td>\n",
       "      <td>2016</td>\n",
       "      <td>ALABAMA</td>\n",
       "      <td>DALE</td>\n",
       "      <td>145.0</td>\n",
       "      <td>USDA_Corn_County_2016.csv</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  commodity_desc reference_period_desc  year state_name county_name target  \\\n",
       "0           CORN                  YEAR  2016    ALABAMA     BALDWIN  152.9   \n",
       "1           CORN                  YEAR  2016    ALABAMA     BARBOUR  188.9   \n",
       "2           CORN                  YEAR  2016    ALABAMA    CHEROKEE   92.3   \n",
       "3           CORN                  YEAR  2016    ALABAMA    CLEBURNE  125.0   \n",
       "4           CORN                  YEAR  2016    ALABAMA      COFFEE  104.5   \n",
       "5           CORN                  YEAR  2016    ALABAMA     COLBERT  126.2   \n",
       "6           CORN                  YEAR  2016    ALABAMA     CONECUH  116.7   \n",
       "7           CORN                  YEAR  2016    ALABAMA   COVINGTON  108.1   \n",
       "8           CORN                  YEAR  2016    ALABAMA     CULLMAN  117.2   \n",
       "9           CORN                  YEAR  2016    ALABAMA        DALE  145.0   \n",
       "\n",
       "                 source_file  \n",
       "0  USDA_Corn_County_2016.csv  \n",
       "1  USDA_Corn_County_2016.csv  \n",
       "2  USDA_Corn_County_2016.csv  \n",
       "3  USDA_Corn_County_2016.csv  \n",
       "4  USDA_Corn_County_2016.csv  \n",
       "5  USDA_Corn_County_2016.csv  \n",
       "6  USDA_Corn_County_2016.csv  \n",
       "7  USDA_Corn_County_2016.csv  \n",
       "8  USDA_Corn_County_2016.csv  \n",
       "9  USDA_Corn_County_2016.csv  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_data = np.load(labels, allow_pickle=True)\n",
    "label_header = np.load(\"labels_header.npy\", allow_pickle=True)\n",
    "label_df = pd.DataFrame(label_data, columns=label_header)\n",
    "label_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dbae3fa7-5e50-4467-8ca0-7a922af25ef5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reshaped histograms shape: (12, 3, 416)\n",
      "Labels shape: (12, 1)\n",
      "Number of filtered combinations: 36\n"
     ]
    }
   ],
   "source": [
    "dataset, input_shape = create_hist_dataset(counties, list(years), months, \"labels_combined.npy\", \"labels_header.npy\")\n",
    "# dataset = dataset.batch(batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "88e51423-1333-4b51-b08d-efa845576b53",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data point shape (after batching): (2, 3, 416)\n",
      "Label shape (after batching): (2,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-18 01:11:27.380506: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_1' with dtype double and shape [3]\n",
      "\t [[{{node Placeholder/_1}}]]\n",
      "2024-10-18 01:11:27.380890: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype double and shape [3,3,416]\n",
      "\t [[{{node Placeholder/_0}}]]\n"
     ]
    }
   ],
   "source": [
    "data = create_data_sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "aa9b17b3-4743-4b17-b4af-04115ce9ea47",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # Assuming you have a dataset named 'dataset'\n",
    "# dataset_path = f'gs://{bucket_name}/dataset/training_small'\n",
    "\n",
    "# # Save the dataset\n",
    "# dataset.save(dataset_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6f40d955-b69d-433c-8339-8aa91957b2f5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data point shape (before batching): (3, 416)\n",
      "Label shape (before batching): (1,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-18 00:50:10.379180: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_1' with dtype float and shape [12,1]\n",
      "\t [[{{node Placeholder/_1}}]]\n"
     ]
    }
   ],
   "source": [
    "# Check the dataset before batching\n",
    "for data_point, label in dataset.take(1):\n",
    "    print(\"Data point shape (before batching):\", data_point.shape)\n",
    "    print(\"Label shape (before batching):\", label.shape)\n",
    "\n",
    "# # Now, batch the dataset\n",
    "# dataset = dataset.batch(batch_size)\n",
    "\n",
    "# # Check the dataset after batching\n",
    "# for data_point, label in dataset.take(1):\n",
    "#     print(\"Data point shape (after batching):\", data_point.shape)\n",
    "#     print(\"Label shape (after batching):\", label.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "83a12278-010a-4b9f-881d-99afc573a007",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-18 00:50:12.536477: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_1' with dtype float and shape [12,1]\n",
      "\t [[{{node Placeholder/_1}}]]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Exception encountered when calling layer 'lstm_model' (type LstmModel).\n\nInput 0 of layer \"lstm\" is incompatible with the layer: expected ndim=3, found ndim=2. Full shape received: (3, 416)\n\nCall arguments received by layer 'lstm_model' (type LstmModel):\n  • inputs=tf.Tensor(shape=(3, 416), dtype=float32)\n  • training=True",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Initialize and train the model\u001b[39;00m\n\u001b[1;32m      3\u001b[0m model \u001b[38;5;241m=\u001b[39m LstmModel(input_shape, lstm_layers\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m, no_units\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m,)\n\u001b[0;32m----> 4\u001b[0m trained_model, history \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_and_evaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/inovation_project/2_gc-pipeline/serving/hist_training.py:97\u001b[0m, in \u001b[0;36mtrain_and_evaluate\u001b[0;34m(model, dataset, validation_split, epochs, learning_rate, patience)\u001b[0m\n\u001b[1;32m     94\u001b[0m train_dataset \u001b[38;5;241m=\u001b[39m dataset\u001b[38;5;241m.\u001b[39mtake(train_size)\n\u001b[1;32m     95\u001b[0m val_dataset \u001b[38;5;241m=\u001b[39m dataset\u001b[38;5;241m.\u001b[39mskip(train_size)            \n\u001b[0;32m---> 97\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     98\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_dataset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     99\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_dataset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    100\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    101\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mearly_stopping\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mMLflowCallback\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    102\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\n\u001b[1;32m    103\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    105\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m model, history\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/keras/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/inovation_project/2_gc-pipeline/serving/hist_training.py:65\u001b[0m, in \u001b[0;36mLstmModel.call\u001b[0;34m(self, inputs, training)\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[38;5;66;03m# Apply LSTM and Dropout layers sequentially\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m layer \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlstm_layers:\n\u001b[0;32m---> 65\u001b[0m     x \u001b[38;5;241m=\u001b[39m layer(x, training\u001b[38;5;241m=\u001b[39mtraining) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(layer, Dropout) \u001b[38;5;28;01melse\u001b[39;00m \u001b[43mlayer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     67\u001b[0m \u001b[38;5;66;03m# Final output layer\u001b[39;00m\n\u001b[1;32m     68\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput_layer(x)\n",
      "\u001b[0;31mValueError\u001b[0m: Exception encountered when calling layer 'lstm_model' (type LstmModel).\n\nInput 0 of layer \"lstm\" is incompatible with the layer: expected ndim=3, found ndim=2. Full shape received: (3, 416)\n\nCall arguments received by layer 'lstm_model' (type LstmModel):\n  • inputs=tf.Tensor(shape=(3, 416), dtype=float32)\n  • training=True"
     ]
    }
   ],
   "source": [
    "# Initialize and train the model\n",
    "\n",
    "model = LstmModel(input_shape, lstm_layers=5, no_units=10,)\n",
    "trained_model, history = train_and_evaluate(model, dataset, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "044be14d-66cb-4467-95ec-2a9824d416ed",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "conda-base-py",
   "name": "workbench-notebooks.m125",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/workbench-notebooks:m125"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel) (Local)",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
