{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bfd8f97a-2d94-4054-94ea-83653ea50636",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\"\"\"Data utilities to grab data from google cloud bucket.\n",
    "\n",
    "Meant to be used for both training and prediction so the model is\n",
    "trained on exactly the same data that will be used for predictions.\n",
    "\"\"\"\n",
    "\n",
    "from __future__ import annotations\n",
    "\n",
    "import io\n",
    "import logging\n",
    "import os\n",
    "import re\n",
    "import tempfile\n",
    "import time\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "from typing import Dict\n",
    "\n",
    "import google.auth\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import rasterio\n",
    "import requests\n",
    "from serving.constants import (\n",
    "    BUCKET,\n",
    "    HIST_BINS_LIST,\n",
    "    HIST_DEST_PREFIX,\n",
    "    IMG_SOURCE_PREFIX,\n",
    "    SELECTED_BANDS,\n",
    "    PROJECT,\n",
    "    PIX_COUNT,\n",
    "    REFLECTANCE_CONST,\n",
    "    NUM_BINS,\n",
    "    MAP_NAN,\n",
    "    NORMALIZE\n",
    ")\n",
    "from google.api_core import exceptions, retry\n",
    "from google.cloud import storage\n",
    "from numpy.lib.recfunctions import structured_to_unstructured\n",
    "from osgeo import gdal\n",
    "from rasterio.io import MemoryFile\n",
    "from serving.common import list_blobs_with_prefix\n",
    "\n",
    "logging.basicConfig(\n",
    "    filename=\"hist.log\",\n",
    "    level=logging.INFO,\n",
    "    format=\"%(asctime)s - %(levelname)s - %(message)s\",\n",
    ")\n",
    "\n",
    "\n",
    "def hist_init():\n",
    "    \"\"\"Authenticate and initialize Earth Engine with the default credentials.\"\"\"\n",
    "    # Use the Earth Engine High Volume endpoint.\n",
    "    #   https://developers.google.com/earth-engine/cloud/highvolume\n",
    "    credentials, project = google.auth.default()\n",
    "\n",
    "def process_band(bucket, blob_name, band, bins, skip_nan, normalise):\n",
    "\n",
    "    storage_client = storage.Client()\n",
    "    blob = storage_client.bucket(bucket).blob(blob_name)\n",
    "\n",
    "    with blob.open(\"rb\") as f:\n",
    "        with rasterio.open(f) as src:\n",
    "\n",
    "            data = src.read(band).flatten()\n",
    "            na_mask = np.isnan(data)\n",
    "            \n",
    "            if skip_nan == False:\n",
    "                data[na_mask] = 0.0\n",
    "                valid_data = data\n",
    "            else:\n",
    "                valid_data = data[~na_mask]\n",
    "                \n",
    "            if normalise:\n",
    "                valid_data = valid_data / REFLECTANCE_CONST\n",
    "                bins = bins / REFLECTANCE_CONST\n",
    "                \n",
    "            valid_max = np.max(valid_data)\n",
    "            valid_min = np.min(valid_data)\n",
    "\n",
    "            if valid_max > bins[-1]:\n",
    "                logging.warning(\n",
    "                    f\"image: {blob_name}, band: {band}, {valid_max} value is larger than assumed possible values for this band: {bins[-1]}\"\n",
    "                )\n",
    "            elif valid_min < bins[0]:\n",
    "                logging.warning(\n",
    "                    f\"image: {blob_name}, band: {band}, {valid_min} value is smaller than assumed possible values for this band {bins[0]}\"\n",
    "                )\n",
    "            \n",
    "            if valid_data.size > 0:\n",
    "                total_sum = np.sum(valid_data)\n",
    "                total_count = valid_data.size\n",
    "                mean = total_sum / total_count\n",
    "                hist, _ = np.histogram(valid_data, bins=bins, density=False)\n",
    "            else:\n",
    "                logging.error(f\"image: {blob_name}, band: {band} has 0 valid pixels. Investigate\")\n",
    "                mean = np.nan\n",
    "                hist = np.zeros_like(\n",
    "                    bins[:-1]\n",
    "                )  # histogram will have one less element than bins\n",
    "\n",
    "    return hist\n",
    "\n",
    "\n",
    "def process_tiff(bucket, blob_name, bin_list, selected_bands, skip_nan, normalise, max_workers=6):\n",
    "    with ThreadPoolExecutor(max_workers=max_workers) as executor:\n",
    "        future_to_band = {\n",
    "            executor.submit(\n",
    "                process_band, bucket, blob_name, band, bins, skip_nan, normalise\n",
    "            ): band\n",
    "            for band, bins in zip(selected_bands, bin_list)\n",
    "        }\n",
    "        results = []\n",
    "\n",
    "        for future in as_completed(future_to_band):\n",
    "            band = future_to_band[future]\n",
    "            try:\n",
    "                result = future.result()\n",
    "                results.append(result)\n",
    "                logging.info(f\"Processed band {band} successfully\")\n",
    "            except Exception as exc:\n",
    "                logging.exception(f\"Band {band} generated an exception: {exc}\")\n",
    "\n",
    "    sorted_results = sorted(results, key=lambda x: x[0])\n",
    "    return np.array(sorted_results).flatten()  # one long array instead of bands\n",
    "\n",
    "\n",
    "def recombine_image(bucket, core_image_name, bin_list, selected_bands, skip_nan=False, normalise=False):\n",
    "    start_time = time.time()\n",
    "\n",
    "    hist_per_blob = []\n",
    "    blobs = list_blobs_with_prefix(core_image_name)\n",
    "    for blob in blobs:\n",
    "        results = process_tiff(bucket, blob.name, bin_list, selected_bands, skip_nan, normalise)\n",
    "        hist_per_blob.append(results)\n",
    "\n",
    "    combined_hist = np.sum(np.array(hist_per_blob), axis=0)\n",
    "\n",
    "    end_time = time.time()\n",
    "    execution_time = end_time - start_time\n",
    "    logging.info(\n",
    "        f\"Image {core_image_name} has been processed in {execution_time/60:.4f} minuntes\"\n",
    "    )\n",
    "\n",
    "    return combined_hist\n",
    "\n",
    "def write_histogram_to_gcs(histogram, bucket_name, blob_name):\n",
    "    \"\"\"\n",
    "    Write a NumPy array (histogram) to Google Cloud Storage.\n",
    "\n",
    "    Args:\n",
    "    histogram (np.array): The histogram to save.\n",
    "    bucket_name (str): The name of the GCS bucket.\n",
    "    blob_name (str): The name to give the file in GCS (including any 'path').\n",
    "\n",
    "    Returns:\n",
    "    str: The public URL of the uploaded file.\n",
    "    \"\"\"\n",
    "    # Ensure the blob_name ends with .npy\n",
    "    if not blob_name.endswith('.npy'):\n",
    "        blob_name += '.npy'\n",
    "\n",
    "    # Create a GCS client\n",
    "    client = storage.Client()\n",
    "\n",
    "    # Get the bucket\n",
    "    bucket = client.bucket(bucket_name)\n",
    "\n",
    "    # Create a blob\n",
    "    blob = bucket.blob(blob_name)\n",
    "\n",
    "    # Convert the numpy array to bytes\n",
    "    array_bytes = io.BytesIO()\n",
    "    np.save(array_bytes, histogram)\n",
    "    array_bytes.seek(0)\n",
    "\n",
    "    # Upload the bytes to GCS\n",
    "    blob.upload_from_file(array_bytes, content_type='application/octet-stream')\n",
    "\n",
    "    logging.info(f\"Histogram uploaded to gs://{bucket_name}/{blob_name}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "50936547-d113-41e2-ad62-5524a415e110",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "image_name=\"images/60/Sutter_06/2021/5-6\"\n",
    "file_name=\"histograms/nan_map_True/norm_True/32_buckets/60/Sutter_06/2021/5-6.npy\"\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "57bfd5f9-29ef-40c3-8a49-3e6ff54951ee",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "hist = recombine_image(BUCKET, image_name, HIST_BINS_LIST, SELECTED_BANDS, MAP_NAN, NORMALIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "57a110a0-e2f7-4a4c-8a5e-85700a4d1ac0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32.0"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "96/3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fbefd41a-ddc5-4323-b70e-bdc649b73487",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([   0,    0,    0,    0,  432, 1695,  593,  289,  175,  101,   86,\n",
       "         80,   82,   78,   46,   52,   33,   19,    9,    7,    8,    4,\n",
       "          1,    1,    1,    3,    1,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,  424, 1971,  592,  310,  132,\n",
       "        141,   96,   81,   19,   17,    9,    3,    1,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    1,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0, 2560,  623,  194,  215,\n",
       "         78,   73,   39,   11,    1,    2,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    1,    0])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "241e67d2-8ba6-465d-9ec0-fe0cbec82e42",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "client = storage.Client()\n",
    "bucket = client.get_bucket(BUCKET)\n",
    "hist_blob = bucket.blob(file_name)\n",
    "content = hist_blob.download_as_bytes()\n",
    "binary_data = io.BytesIO(content)\n",
    "array = np.load(binary_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8c79f65a-dc4f-4046-8689-ff31708baf00",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([   0,    0,    0,    0,    0,    0,    0,  424, 1971,  592,  310,\n",
       "        132,  141,   96,   81,   19,   17,    9,    3,    1,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    1,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0, 2560,  623,  194,\n",
       "        215,   78,   73,   39,   11,    1,    2,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    1,    0,    0,    0,\n",
       "          0,    0,  432, 1695,  593,  289,  175,  101,   86,   80,   82,\n",
       "         78,   46,   52,   33,   19,    9,    7,    8,    4,    1,    1,\n",
       "          1,    3,    1,    0,    0,    0,    0,    0])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4c348838-e3c1-43f0-89cc-0a2fff908dcb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "lstm_hist = hist.reshape(-1,3,32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5be0da4b-7f4c-4101-a2ad-fd5b03031fdd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[   0,    0,    0,    0,  432, 1695,  593,  289,  175,  101,\n",
       "           86,   80,   82,   78,   46,   52,   33,   19,    9,    7,\n",
       "            8,    4,    1,    1,    1,    3,    1,    0,    0,    0,\n",
       "            0,    0],\n",
       "        [   0,    0,    0,    0,    0,    0,    0,  424, 1971,  592,\n",
       "          310,  132,  141,   96,   81,   19,   17,    9,    3,    1,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            1,    0],\n",
       "        [   0,    0,    0,    0,    0,    0,    0,    0,    0, 2560,\n",
       "          623,  194,  215,   78,   73,   39,   11,    1,    2,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            1,    0]]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lstm_hist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a891835-79b7-46ce-b8fe-2ad8f70f0753",
   "metadata": {},
   "outputs": [],
   "source": [
    "[[0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00\n",
    "  4.240e+02 1.971e+03 5.920e+02 3.100e+02 1.320e+02 1.410e+02 9.600e+01\n",
    "  8.100e+01 1.900e+01 1.700e+01 9.000e+00 3.000e+00 1.000e+00 0.000e+00\n",
    "  0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00\n",
    "  0.000e+00 0.000e+00 1.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00\n",
    "  0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00 2.560e+03\n",
    "  6.230e+02 1.940e+02 2.150e+02 7.800e+01 7.300e+01 3.900e+01 1.100e+01\n",
    "  1.000e+00 2.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00\n",
    "  0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00 1.000e+00\n",
    "  0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00 4.320e+02 1.695e+03\n",
    "  5.930e+02 2.890e+02 1.750e+02 1.010e+02 8.600e+01 8.000e+01 8.200e+01\n",
    "  7.800e+01 4.600e+01 5.200e+01 3.300e+01 1.900e+01 9.000e+00 7.000e+00\n",
    "  8.000e+00 4.000e+00 1.000e+00 1.000e+00 1.000e+00 3.000e+00 1.000e+00\n",
    "  0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00]\n",
    " [0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00 1.620e+02\n",
    "  4.270e+02 6.760e+02 7.660e+02 6.520e+02 3.570e+02 2.740e+02 1.860e+02\n",
    "  1.190e+02 8.800e+01 3.600e+01 2.200e+01 1.400e+01 7.000e+00 2.000e+00\n",
    "  2.000e+00 0.000e+00 2.000e+00 5.000e+00 0.000e+00 0.000e+00 0.000e+00\n",
    "  0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00\n",
    "  0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00 1.500e+01 4.750e+02\n",
    "  1.490e+03 1.082e+03 3.700e+02 2.090e+02 9.600e+01 3.800e+01 1.100e+01\n",
    "  6.000e+00 3.000e+00 0.000e+00 0.000e+00 1.000e+00 0.000e+00 1.000e+00\n",
    "  0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00\n",
    "  0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00\n",
    "  0.000e+00 0.000e+00 0.000e+00 0.000e+00 3.860e+02 1.641e+03 1.196e+03\n",
    "  3.960e+02 1.200e+02 4.000e+01 1.500e+01 1.000e+00 0.000e+00 0.000e+00\n",
    "  0.000e+00 1.000e+00 0.000e+00 1.000e+00 0.000e+00 0.000e+00 0.000e+00\n",
    "  0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00]\n",
    " [0.000e+00 0.000e+00 0.000e+00 0.000e+00 1.000e+00 7.000e+00 4.600e+01\n",
    "  7.600e+01 6.300e+01 3.400e+01 3.400e+01 1.040e+02 1.340e+02 1.390e+02\n",
    "  2.230e+02 2.930e+02 3.070e+02 3.360e+02 2.480e+02 1.100e+02 7.400e+01\n",
    "  9.900e+01 1.540e+02 1.670e+02 1.760e+02 1.650e+02 1.850e+02 1.340e+02\n",
    "  1.230e+02 1.720e+02 6.600e+01 5.000e+01 0.000e+00 0.000e+00 0.000e+00\n",
    "  0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00 3.400e+01\n",
    "  1.560e+02 2.130e+02 4.160e+02 4.730e+02 3.800e+02 5.910e+02 4.660e+02\n",
    "  5.330e+02 4.050e+02 1.130e+02 9.000e+00 7.000e+00 0.000e+00 1.000e+00\n",
    "  0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00\n",
    "  0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00\n",
    "  0.000e+00 6.000e+00 9.200e+01 9.200e+01 2.160e+02 3.770e+02 4.050e+02\n",
    "  2.580e+02 3.220e+02 4.160e+02 2.010e+02 3.070e+02 3.290e+02 3.530e+02\n",
    "  2.510e+02 1.490e+02 7.000e+00 7.000e+00 9.000e+00 0.000e+00 0.000e+00\n",
    "  0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c67bd073-b0de-4fa2-af75-d39d768c1285",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 3, 32)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lstm_hist.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "82599b45-3dc3-46a1-9607-3376249efe3f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "skip_nan = True\n",
    "normalise = True\n",
    "bins = HIST_BINS_LIST[0]\n",
    "blob_name = \"images/60/Sutter_06/2021/5-6.tif\"\n",
    "storage_client = storage.Client()\n",
    "blob = storage_client.bucket(BUCKET).blob(blob_name)\n",
    "band = 2\n",
    "with blob.open(\"rb\") as f:\n",
    "    with rasterio.open(f) as src:\n",
    "\n",
    "        data = src.read(band).flatten()\n",
    "        na_mask = np.isnan(data)\n",
    "\n",
    "        if skip_nan == False:\n",
    "            data[na_mask] = 0.0\n",
    "            valid_data = data\n",
    "        else:\n",
    "            valid_data = data[~na_mask]\n",
    "\n",
    "        if normalise:\n",
    "            valid_data = valid_data / REFLECTANCE_CONST\n",
    "            bins = bins / REFLECTANCE_CONST\n",
    "\n",
    "        valid_max = np.max(valid_data)\n",
    "        valid_min = np.min(valid_data)\n",
    "\n",
    "        if valid_max > bins[-1]:\n",
    "            logging.warning(\n",
    "                f\"image: {blob_name}, band: {band}, {valid_max} value is larger than assumed possible values for this band: {bins[-1]}\"\n",
    "            )\n",
    "        elif valid_min < bins[0]:\n",
    "            logging.warning(\n",
    "                f\"image: {blob_name}, band: {band}, {valid_min} value is smaller than assumed possible values for this band {bins[0]}\"\n",
    "            )\n",
    "\n",
    "        if valid_data.size > 0:\n",
    "            total_sum = np.sum(valid_data)\n",
    "            total_count = valid_data.size\n",
    "            mean = total_sum / total_count\n",
    "            hist, _ = np.histogram(valid_data, bins=bins, density=False)\n",
    "        else:\n",
    "            logging.error(f\"image: {blob_name}, band: {band} has 0 valid pixels. Investigate\")\n",
    "            mean = np.nan\n",
    "            hist = np.zeros_like(\n",
    "                bins[:-1]\n",
    "            ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "917bbffa-30c8-453e-9abd-21209f82354d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([nan, nan, nan, ..., nan, nan, nan], dtype=float32)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0dfd3daa-d88a-4e89-8288-143d9ce8c6dd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1050460"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "db038b5d-3139-41e3-bc74-beb9803999db",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.09785, 0.10395, 0.0999 , ..., 0.1089 , 0.1187 , 0.1149 ],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "9e27790a-aac2-44e6-8e0f-de3ec5831d6c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sorted_valid_data = sorted(valid_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "47d15df3-d918-471c-aa2c-20b485f40ea5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[np.float32(0.1533),\n",
       " np.float32(0.1605),\n",
       " np.float32(0.1694),\n",
       " np.float32(0.17225),\n",
       " np.float32(0.28635)]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted_valid_data[-5:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "185af6ac-425b-4177-9b2d-75397a8ae957",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3797"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sorted_valid_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "49c7dc32-8262-45cf-8dd2-c9c911e61e4d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(3797.0)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(array)/3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07a79830-cf05-46ae-973e-d56c9bb9bc66",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "conda-env-gdal_conda-gdal_conda",
   "name": "workbench-notebooks.m125",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/workbench-notebooks:m125"
  },
  "kernelspec": {
   "display_name": "GDAL_kernel (Local)",
   "language": "python",
   "name": "conda-env-gdal_conda-gdal_conda"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
